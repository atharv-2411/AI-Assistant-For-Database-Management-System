import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const response = await openai.chat.completions.create({
  model: "gpt-4o-mini",
  messages: [
    {
      "role": "system",
      "content": [
        {
          "text": "You are a data generation specialist with expertise in PostgreSQL. Your task is to generate realistic and schema-compliant mock data based on provided PostgreSQL CREATE TABLE SQL statements.\n\nInstructions:\n\n    Input:\n        You will receive PostgreSQL CREATE TABLE SQL statements as input. These statements may include comments indicating table numbers and relationships.\n        The SQL will define tables with their columns, data types, constraints (e.g., PRIMARY KEY, FOREIGN KEY, NOT NULL, UNIQUE), and relationships.\n\n    Task:\n        Parse the provided SQL statements to extract information about tables, columns, data types, constraints, and relationships.\n        Generate mock data that adheres to the schema rules and constraints.\n        The mock data should be realistic, varied, and suitable for testing purposes.\n\n    Requirements:\n\n        Data Generation:\n            Data Types: Generate appropriate and realistic data based on column data types (e.g., realistic names for VARCHAR, valid dates for DATE, etc.).\n            Constraints:\n                NOT NULL: Ensure that all columns marked as NOT NULL have valid data.\n                UNIQUE: Ensure that columns marked as UNIQUE contain unique values across all records.\n                PRIMARY KEY: Generate unique values for primary key columns.\n                FOREIGN KEY: Ensure that foreign key values correctly reference existing records in the related tables.\n            Relationships: Maintain referential integrity by correctly linking related tables based on foreign keys.\n            Default Values: If columns have default values, apply them appropriately unless overridden by mock data.\n            Auto-Increment Fields: Handle auto-incrementing primary keys by generating sequential or unique identifiers as required.\n\n        Output Format:\n            Option 1: SQL INSERT Statements\n                Generate INSERT INTO statements for each table with mock data.\n                Ensure that the order of insertion respects foreign key dependencies (i.e., parent tables first).\n            Option 2: JSON Data\n                Generate JSON objects for each table containing arrays of mock records.\n                Ensure that foreign key relationships are correctly represented by referencing existing records.\n\n        Number of Records:\n            Allow specification of the number of mock records per table (e.g., 10 records per table). If not specified, default to a reasonable number (e.g., 10).\n\n        Formatting:\n            Ensure that the mock data is well-formatted, readable, and free of syntax errors.\n            If asked, For SQL INSERT statements, maintain proper SQL syntax and formatting.\n            Default: For JSON data, ensure valid JSON structure with proper nesting and data types.\n\n    Constraints:\n        Do Not:\n            Output any text or explanations outside of the mock data content.\n            Include any additional properties or modify the required format.\n        Ensure:\n            The mock data strictly adheres to the provided schema's constraints and relationships.\n            All identifiers (table names, column names) are consistent and correctly referenced.\n            The data is realistic and varied to effectively simulate real-world scenarios.\n            The output is syntactically correct and free from errors.\nExample:\njson data\n{\n  \"Authors\": [\n    {\n      \"author_id\": 1,\n      \"first_name\": \"John\",\n      \"last_name\": \"Doe\",\n      \"birth_year\": 1975\n    },\n    {\n      \"author_id\": 2,\n      \"first_name\": \"Jane\",\n      \"last_name\": \"Smith\",\n      \"birth_year\": 1980\n    },\n    {\n      \"author_id\": 3,\n      \"first_name\": \"Emily\",\n      \"last_name\": \"Johnson\",\n      \"birth_year\": 1990\n    }\n  ],\n  \"Books\": [\n    {\n      \"book_id\": 1,\n      \"title\": \"The Great Adventure\",\n      \"genre\": \"Adventure\",\n      \"publish_year\": 2005,\n      \"author_id\": 1\n    },\n    {\n      \"book_id\": 2,\n      \"title\": \"Mystery of the Night\",\n      \"genre\": \"Mystery\",\n      \"publish_year\": 2010,\n      \"author_id\": 2\n    },\n    {\n      \"book_id\": 3,\n      \"title\": \"Learning Go\",\n      \"genre\": \"Education\",\n      \"publish_year\": 2020,\n      \"author_id\": 3\n    }\n  ]\n}\n\nsql\n\n-- Mock Data for Authors Table\nINSERT INTO Authors (author_id, first_name, last_name, birth_year) VALUES\n(1, 'John', 'Doe', 1975),\n(2, 'Jane', 'Smith', 1980),\n(3, 'Emily', 'Johnson', 1990);\n\n-- Mock Data for Books Table\nINSERT INTO Books (book_id, title, genre, publish_year, author_id) VALUES\n(1, 'The Great Adventure', 'Adventure', 2005, 1),\n(2, 'Mystery of the Night', 'Mystery', 2010, 2),\n(3, 'Learning Go', 'Education', 2020, 3);\n\n\nNow, based on the provided PostgreSQL CREATE TABLE statements, generate realistic and schema-compliant mock data in both SQL INSERT statements and JSON formats as shown in the examples. Ensure that all constraints are respected and relationships are accurately maintained.",
          "type": "text"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "create me json mock data for \n\n\n-- 1. Coffee Types Table\nCREATE TABLE coffee_types (\n    coffee_type_id SERIAL PRIMARY KEY, -- Unique identifier for each coffee type\n    name VARCHAR(100) NOT NULL, -- Name of the coffee type\n    description TEXT, -- Description of the coffee type\n    price NUMERIC(5,2) NOT NULL -- Price of the coffee type\n);\n\n-- 2. Employees Table\nCREATE TABLE employees (\n    employee_id SERIAL PRIMARY KEY, -- Unique identifier for each employee\n    first_name VARCHAR(100) NOT NULL, -- Employee's first name\n    last_name VARCHAR(100) NOT NULL, -- Employee's last name\n    email VARCHAR(255) NOT NULL UNIQUE, -- Employee's email (must be unique)\n    hire_date DATE NOT NULL -- Date the employee was hired\n);\n\n-- 3. Orders Table\nCREATE TABLE orders (\n    order_id SERIAL PRIMARY KEY, -- Unique identifier for each order\n    employee_id INT, -- Employee who took the order\n    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- Date and time of the order\n    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) -- Foreign key constraint\n);\n\n-- 4. Order Items Table (Many-to-many relationship between Orders and Coffee Types)\nCREATE TABLE order_items (\n    order_item_id SERIAL PRIMARY KEY, -- Unique identifier for each order item\n    order_id INT, -- Related order\n    coffee_type_id INT, -- Related coffee type\n    quantity INT NOT NULL DEFAULT 1, -- Quantity of the coffee type ordered\n    FOREIGN KEY (order_id) REFERENCES orders(order_id), -- Foreign key constraint\n    FOREIGN KEY (coffee_type_id) REFERENCES coffee_types(coffee_type_id) -- Foreign key constraint\n);\n"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "{\n  \"coffee_types\": [\n    {\n      \"coffee_type_id\": 1,\n      \"name\": \"Espresso\",\n      \"description\": \"A strong and concentrated coffee brewed by forcing hot water through finely-ground coffee.\",\n      \"price\": 2.50\n    },\n    {\n      \"coffee_type_id\": 2,\n      \"name\": \"Latte\",\n      \"description\": \"A creamy coffee made with espresso and steamed milk, topped with a small amount of milk foam.\",\n      \"price\": 3.50\n    },\n    {\n      \"coffee_type_id\": 3,\n      \"name\": \"Cappuccino\",\n      \"description\": \"A coffee drink made with equal parts espresso, steamed milk, and milk foam.\",\n      \"price\": 4.00\n    },\n    {\n      \"coffee_type_id\": 4,\n      \"name\": \"Americano\",\n      \"description\": \"A diluted espresso made by adding hot water to espresso shots.\",\n      \"price\": 2.80\n    },\n    {\n      \"coffee_type_id\": 5,\n      \"name\": \"Mocha\",\n      \"description\": \"A delicious blend of espresso, steamed milk, and chocolate syrup, often topped with whipped cream.\",\n      \"price\": 4.50\n    }\n  ],\n  \"employees\": [\n    {\n      \"employee_id\": 1,\n      \"first_name\": \"Alice\",\n      \"last_name\": \"Johnson\",\n      \"email\": \"alice.johnson@example.com\",\n      \"hire_date\": \"2020-05-15\"\n    },\n    {\n      \"employee_id\": 2,\n      \"first_name\": \"Bob\",\n      \"last_name\": \"Smith\",\n      \"email\": \"bob.smith@example.com\",\n      \"hire_date\": \"2019-08-22\"\n    },\n    {\n      \"employee_id\": 3,\n      \"first_name\": \"Charlie\",\n      \"last_name\": \"Davis\",\n      \"email\": \"charlie.davis@example.com\",\n      \"hire_date\": \"2021-01-10\"\n    },\n    {\n      \"employee_id\": 4,\n      \"first_name\": \"Diana\",\n      \"last_name\": \"Garcia\",\n      \"email\": \"diana.garcia@example.com\",\n      \"hire_date\": \"2022-03-30\"\n    },\n    {\n      \"employee_id\": 5,\n      \"first_name\": \"Evan\",\n      \"last_name\": \"Martinez\",\n      \"email\": \"evan.martinez@example.com\",\n      \"hire_date\": \"2018-11-25\"\n    }\n  ],\n  \"orders\": [\n    {\n      \"order_id\": 1,\n      \"employee_id\": 1,\n      \"order_date\": \"2023-10-01T10:00:00\"\n    },\n    {\n      \"order_id\": 2,\n      \"employee_id\": 2,\n      \"order_date\": \"2023-10-01T11:30:00\"\n    },\n    {\n      \"order_id\": 3,\n      \"employee_id\": 1,\n      \"order_date\": \"2023-10-01T12:15:00\"\n    },\n    {\n      \"order_id\": 4,\n      \"employee_id\": 3,\n      \"order_date\": \"2023-10-01T14:00:00\"\n    },\n    {\n      \"order_id\": 5,\n      \"employee_id\": 4,\n      \"order_date\": \"2023-10-01T15:45:00\"\n    }\n  ],\n  \"order_items\": [\n    {\n      \"order_item_id\": 1,\n      \"order_id\": 1,\n      \"coffee_type_id\": 1,\n      \"quantity\": 2\n    },\n    {\n      \"order_item_id\": 2,\n      \"order_id\": 1,\n      \"coffee_type_id\": 3,\n      \"quantity\": 1\n    },\n    {\n      \"order_item_id\": 3,\n      \"order_id\": 2,\n      \"coffee_type_id\": 2,\n      \"quantity\": 3\n    },\n    {\n      \"order_item_id\": 4,\n      \"order_id\": 3,\n      \"coffee_type_id\": 5,\n      \"quantity\": 4\n    },\n    {\n      \"order_item_id\": 5,\n      \"order_id\": 4,\n      \"coffee_type_id\": 4,\n      \"quantity\": 2\n    },\n    {\n      \"order_item_id\": 6,\n      \"order_id\": 5,\n      \"coffee_type_id\": 1,\n      \"quantity\": 1\n    }\n  ]\n}"
        }
      ]
    }
  ],
  temperature: 1,
  max_tokens: 2048,
  top_p: 1,
  frequency_penalty: 0,
  presence_penalty: 0,
  response_format: {
    "type": "text"
  },
});
